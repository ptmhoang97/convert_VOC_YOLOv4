{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNN1T42xyG2N9u/OygT81ak",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ptmhoang97/process_dataset/blob/main/rename_and_split_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive._mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU82I4E9B9U1",
        "outputId": "46cfa2cf-1b5f-4fa8-eedd-c08c73ec0700"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose dataset to unzip\n",
        "dataset_name = \"coco2017_train_truck_VOC\""
      ],
      "metadata": {
        "id": "ghPSrPpbCGjT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/gdrive/MyDrive/_dataset/{0}.zip\".format(dataset_name)\n",
        "dataset_unzip_path = \"/content\"\n",
        "!unzip {dataset_path} -d {dataset_unzip_path}"
      ],
      "metadata": {
        "id": "RSmh5obaCHws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Pv0W7w04BbAp"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import fnmatch\n",
        "\n",
        "def convert_png_to_jpg(file_location):\n",
        "    pattern = '*.png'\n",
        "    image_path = []\n",
        "    for path in fnmatch.filter(os.listdir(file_location), pattern):\n",
        "        full_path = os.path.join(file_location, path)\n",
        "        if os.path.isfile(full_path):\n",
        "            image_path.append(full_path)\n",
        "    \n",
        "    if not image_path:\n",
        "        print(\"No png images\")\n",
        "    else:\n",
        "        print(\"Converting png to jpg ...\")\n",
        "        for path in image_path:\n",
        "            path_png = '{}'.format(path)\n",
        "            path_jpg = path_png.replace(\".png\",\".jpg\")\n",
        "            \n",
        "            # Convert the link with '\\' to '\\\\' so that it can pass to Image.open() \n",
        "            path_png = path_png.encode('unicode-escape').decode()\n",
        "            path_jpg = path_jpg.encode('unicode-escape').decode()\n",
        "\n",
        "            img_png = Image.open(path_png)\n",
        "            img_png_rbg = img_png.convert('RGB')\n",
        "            img_png_rbg.save(path_jpg)\n",
        "        print(\"Done converting!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import fnmatch\n",
        "\n",
        "def delete_all_png(file_location):\n",
        "    pattern = '*.png'\n",
        "    image_path = []\n",
        "    for path in fnmatch.filter(os.listdir(file_location), pattern):\n",
        "        full_path = os.path.join(file_location, path)\n",
        "        if os.path.isfile(full_path):\n",
        "            image_path.append(full_path)\n",
        "\n",
        "    if not image_path:\n",
        "        print(\"No png images\")\n",
        "    else:\n",
        "        print(\"Deleting all png ...\")\n",
        "        for images in test:\n",
        "            if images.endswith(\".png\"):\n",
        "                os.remove(os.path.join(file_location, images))\n",
        "        print(\"Done deleting!\")"
      ],
      "metadata": {
        "id": "dsjpL80QDPJ9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import fnmatch\n",
        "import shutil\n",
        "\n",
        "def returnNotMatches(a, b):\n",
        "    return [[x for x in a if x not in b], [x for x in b if x not in a]]\n",
        "\n",
        "def filter_files(file_location,type_file):\n",
        "    pattern = \"*.{}\".format(type_file)\n",
        "    paths = []\n",
        "    for path in fnmatch.filter(os.listdir(file_location), pattern):\n",
        "        path = path[:-4]\n",
        "        paths.append(path)\n",
        "    return paths\n",
        "\n",
        "def check_pair_dataset(file_location,type_file_pic,type_file_anno):\n",
        "    path_jpg = filter_files(file_location,type_file_pic)\n",
        "    path_txt = filter_files(file_location,type_file_anno)\n",
        "\n",
        "    for path in path_txt:\n",
        "        if path == \"classes\":\n",
        "            path_txt.remove(\"classes\")\n",
        "    print(\"Checking pair dataset ...\")\n",
        "    if returnNotMatches(path_jpg,path_txt)[0]:\n",
        "        raise Exception(\"Files \" + type_file_pic + \": \" + str(returnNotMatches(path_jpg,path_txt)[0]) + \" miss \" + type_file_anno + \" files\")\n",
        "    elif returnNotMatches(path_jpg,path_txt)[1]:\n",
        "        raise Exception(\"Files \" + type_file_anno + \": \" + str(returnNotMatches(path_jpg,path_txt)[1]) + \" miss \" + type_file_pic + \" files\")\n",
        "    else:\n",
        "        pass\n",
        "    print(\"Done checking! No mismtach!\")"
      ],
      "metadata": {
        "id": "Elyt0hSSEtU2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import fnmatch\n",
        "\n",
        "def rename_file_with_order(file_location,name_file,start_count_number,type_file):\n",
        "    pattern = \"*.{}\".format(type_file)\n",
        "    file_path = []\n",
        "    for path in fnmatch.filter(os.listdir(file_location), pattern):\n",
        "        full_path = os.path.join(file_location, path)\n",
        "        if os.path.isfile(full_path):\n",
        "            file_path.append(full_path)\n",
        "\n",
        "    temp_count = start_count_number\n",
        "    \n",
        "    for path in file_path:\n",
        "        name = \"{0}_{1}\".format(name_file,temp_count)\n",
        "        start = path.rfind(\"/\")\n",
        "        end = path.rfind(\".\")\n",
        "\n",
        "        start_part = path[:start+1]\n",
        "        end_part = path[end:]\n",
        "        \n",
        "        old_name = path\n",
        "        new_name = start_part + name + end_part\n",
        "        \n",
        "        # print(\"***\")\n",
        "        # print(old_name)\n",
        "        print(new_name)\n",
        "        \n",
        "        os.rename(old_name,new_name)\n",
        "        temp_count+=1\n",
        "\n",
        "def rename_picFile_and_annoFile_with_order(file_location,name_file,start_count_number,type_pic_file,type_anno_file):\n",
        "    print(\"Renaming files ...\")\n",
        "\n",
        "    # Rename pic file\n",
        "    rename_file_with_order(file_location,name_file,start_count_number,type_pic_file)  \n",
        "    # Rename anno file\n",
        "    rename_file_with_order(file_location,name_file,start_count_number,type_anno_file)"
      ],
      "metadata": {
        "id": "w6jEF8X0HRHX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "import shutil\n",
        "import re\n",
        "import tqdm\n",
        "\n",
        "import math\n",
        "\n",
        "def round_up_to_even(f):\n",
        "    return math.ceil(f / 2.) * 2\n",
        "\n",
        "def split_dataset(file_location,scale_train):\n",
        "    print(\"Splitting dataset ...\")\n",
        "    paths = {\n",
        "        'TRAIN_PATH': os.path.join(file_location,\"train\"),\n",
        "        'TEST_PATH': os.path.join(file_location,\"test\"),\n",
        "    }\n",
        "\n",
        "    # If using labelimg to create dataset, collect classes from \"classes.txt\" and remove file.     \n",
        "    classes = []\n",
        "    dirs = os.listdir(file_location)\n",
        "    for file_name in dirs:\n",
        "        if file_name == \"classes.txt\":\n",
        "            full_path = os.path.join(file_location, file_name)\n",
        "            with open(full_path,\"r\") as f:\n",
        "                classes_temp = f.readlines()\n",
        "                for cls in classes_temp:\n",
        "                    if cls.endswith(\"\\n\"):\n",
        "                        classes.append(cls[:-1])\n",
        "                    else:\n",
        "                        classes.append(cls)\n",
        "            os.remove(full_path)\n",
        "    \n",
        "    dirs = os.listdir(file_location)\n",
        "    total_dataset = len(dirs)\n",
        "    #print(total_dataset)\n",
        "    #print(dirs)\n",
        "    num_train_dataset = round_up_to_even(total_dataset*scale_train)\n",
        "\n",
        "    # print(\"num_train_dataset: \" + str(num_train_dataset))\n",
        "    # print(\"num_test_dataset: \" + str(total_dataset - num_train_dataset))\n",
        "\n",
        "    for path in paths.values():\n",
        "        if not os.path.exists(path):\n",
        "            os.mkdir(path)\n",
        "            # print(\"Create: \" + path)\n",
        "    \n",
        "    try:\n",
        "        dirs.remove(\"_darknet.labels\")\n",
        "        dirs.remove(\"classes.txt\")\n",
        "    except Exception:\n",
        "        pass\n",
        "    \n",
        "    dirs_temp = ['truck_COCO_2121.xml', 'truck_COCO_5771.jpg', 'truck_COCO_2835.jpg']\n",
        "    dirs_temp.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
        "    print(dirs_temp)\n",
        "\n",
        "    dirs.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
        "    #print(dirs)\n",
        "\n",
        "\n",
        "    for idx,files in enumerate(tqdm(dirs)):\n",
        "        # print(files)\n",
        "        if idx < num_train_dataset:\n",
        "            shutil.move(os.path.join(file_location,files),paths['TRAIN_PATH'])\n",
        "        else:\n",
        "            shutil.move(os.path.join(file_location,files),paths['TEST_PATH'])\n",
        "'''\n",
        "    \n",
        "    with open(os.path.join(paths['TRAIN_PATH'],\"_darknet.labels\"),\"w\") as f:\n",
        "        for cls in classes:\n",
        "            f.write(cls + \"\\n\")\n",
        "    \n",
        "    with open(os.path.join(paths['TEST_PATH'],\"_darknet.labels\"),\"w\") as f:\n",
        "        for cls in classes:\n",
        "            f.write(cls + \"\\n\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "cellView": "code",
        "id": "_McVyqM2Njb4",
        "outputId": "70e5e318-3535-4a0a-833c-8d1873c68f42"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n    \\n    with open(os.path.join(paths[\\'TRAIN_PATH\\'],\"_darknet.labels\"),\"w\") as f:\\n        for cls in classes:\\n            f.write(cls + \"\\n\")\\n    \\n    with open(os.path.join(paths[\\'TEST_PATH\\'],\"_darknet.labels\"),\"w\") as f:\\n        for cls in classes:\\n            f.write(cls + \"\\n\")\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_location = \"/content/{0}\".format(dataset_name)"
      ],
      "metadata": {
        "id": "pRT5Up55BpHl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_png_to_jpg(file_location)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEzeVuPgByxT",
        "outputId": "07f226c1-031b-47c1-9ad8-67ed33c01dde"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No png images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "delete_all_png(file_location)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeZyCJ7SB4Ra",
        "outputId": "7e52873a-7fe6-4f95-cf63-eb6feae7e4f8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No png images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_pair_dataset(file_location,\"jpg\",\"xml\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVLQIoT7EDdE",
        "outputId": "37e33588-37e5-4fe4-ee4d-63392c2fce76"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking pair dataset ...\n",
            "Done checking! No mismtach!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rename_picFile_and_annoFile_with_order(file_location,\"truck_COCO\",0,\"jpg\",\"xml\")"
      ],
      "metadata": {
        "id": "eL3hsm5wE3pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset(file_location,0.8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "M2bnwYmJH1v1",
        "outputId": "5758fc67-f640-4ab9-8431-7f6e574bc6c3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting dataset ...\n",
            "['truck_COCO_2121.xml', 'truck_COCO_2835.jpg', 'truck_COCO_5771.jpg']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-61382f71116b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msplit_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-fbfc4b018f47>\u001b[0m in \u001b[0;36msplit_dataset\u001b[0;34m(file_location, scale_train)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirs_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mdirs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\D'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;31m#print(dirs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-fbfc4b018f47>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirs_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mdirs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\D'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;31m#print(dirs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "A4SNVRpkQ1Ln"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}